{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import  RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from neo4j import GraphDatabase\n",
    "from yfiles_jupyter_graphs import GraphWidget\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars\n",
    "import os\n",
    "from neo4j import  Driver\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOLT_URL =  \"\"\n",
    "USERNAME =  \"\"\n",
    "PASSWORD =  \"\"\n",
    "DATABASE =  \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Neo4j successfully!\n",
      "Query result: []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Create a Neo4j connection class\n",
    "class Neo4jConnection:\n",
    "    def __init__(self, uri, user, password):\n",
    "        try:\n",
    "            self._driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "            print(\"Connected to Neo4j successfully!\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to create the driver: {e}\")\n",
    "    \n",
    "    def close(self):\n",
    "        if self._driver:\n",
    "            self._driver.close()\n",
    "    \n",
    "    def query(self, query, parameters=None):\n",
    "        try:\n",
    "            with self._driver.session(database=DATABASE) as session:\n",
    "                result = session.run(query, parameters)\n",
    "                return [record for record in result]\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Query failed: {e}\")\n",
    "\n",
    "# Initialize connection\n",
    "try:\n",
    "    conn = Neo4jConnection(BOLT_URL, USERNAME, PASSWORD)\n",
    "    # Example query to test the connection\n",
    "    test_query = \"MATCH (n) RETURN n LIMIT 5\"\n",
    "    result = conn.query(test_query)\n",
    "    print(\"Query result:\", result)\n",
    "finally:\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph=Neo4jGraph(\n",
    "    url=BOLT_URL,\n",
    "    username=USERNAME,\n",
    "    password=PASSWORD,\n",
    "    database=DATABASE\n",
    ")\n",
    "\n",
    "# Optional to Clear the graph database\n",
    "cypher = \"\"\"\n",
    "    MATCH (n)\n",
    "    DETACH DELETE n;\n",
    "\"\"\"\n",
    "graph.query(cypher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "loader = TextLoader(file_path=\"dummy_data.txt\")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=24)\n",
    "documents = text_splitter.split_documents(documents=docs)\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGroq(groq_api_key=groq_api_key,model_name=\"llama-3.1-8b-instant\")\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_graph_documents(\n",
    "    graph_documents,\n",
    "    baseEntityLabel=True,#additional __entity__ will be created \n",
    "    include_source=True #this will create mentions relationship to determine the source document\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cypher = \"\"\"\n",
    "    CREATE FULLTEXT INDEX `fulltext_entity_id` FOR (n:__Entity__) ON EACH [n.id]\n",
    "    \"\"\"\n",
    "    graph.query(cypher)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\",\n",
    "    model_kwargs={\"device\": 'cpu'},\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")\n",
    "\n",
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    embeddings,\n",
    "    url=BOLT_URL,\n",
    "    username=USERNAME,\n",
    "    password=PASSWORD,\n",
    "    database = DATABASE,\n",
    "    search_type=\"hybrid\",\n",
    "    node_label=\"Document\",\n",
    "    text_node_properties=[\"text\"],\n",
    "    embedding_node_property=\"embedding\"\n",
    ")\n",
    "vector_retriever = vector_index.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entities(names=['Nonna Lucia'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract entities from given input\n",
    "class Entities(BaseModel):\n",
    "    \"\"\"Identifying information about entities.\"\"\"\n",
    "\n",
    "    names: list[str] = Field(\n",
    "        ...,\n",
    "        description=\"All the person, organization, or business entities that \"\n",
    "        \"appear in the text\",\n",
    "    )\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are extracting organization and person entities from the text.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Use the given format to extract information from the following \"\n",
    "            \"input: {question}\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "entity_chain = llm.with_structured_output(Entities)\n",
    "entity_chain.invoke(\"Who is Nonna Lucia?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fulltext index query\n",
    "def graph_retriever(question: str) -> str:\n",
    "    \"\"\"\n",
    "Note: we made sure that we turned on the baseEntityLabel while adding the documents to the graph then only this fulltext query will work\n",
    "Step1: get the query and extract the entities\n",
    "Step2: for each entity find the nodes using fulltext_entity_id\n",
    "Step3: for each node get all the incoming and outgoing relationships and finally limit the output to 50. Note because we added the source documents we can exclude the Mentions relationship\n",
    "    \"\"\"\n",
    "    result = \"\"\n",
    "    entities = entity_chain.invoke(question)\n",
    "    for entity in entities.names:\n",
    "        response = graph.query(\n",
    "            \"\"\" CALL db.index.fulltext.queryNodes('fulltext_entity_id', $query, {limit:2})\n",
    "                YIELD node, score\n",
    "                WITH node\n",
    "                MATCH (node)-[r:!MENTIONS]->(neighbor)\n",
    "                RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\n",
    "                UNION \n",
    "                MATCH (node)<-[r:!MENTIONS]-(neighbor)\n",
    "                RETURN neighbor.id + ' - ' + type(r) + ' -> ' + node.id AS output\n",
    "                LIMIT 50\n",
    "            \"\"\",\n",
    "            {\"query\": entity},\n",
    "        )\n",
    "        result += \"\\n\".join([el['output'] for el in response])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonna Lucia - ANCESTOR -> Pietro\n",
      "Lucia - OWNER -> Kitchen\n",
      "Lucia - OWNER -> Bella Vita\n",
      "Lucia - SISTER -> Antonio\n",
      "Lucia - GRANDMOTHER -> Amico\n",
      "Lucia - MATRIARCH -> Caruso\n",
      "Lucia - MEMBER -> Caruso Family\n",
      "Lucia - LIVES_IN -> Los Angeles\n",
      "Lucia - TEACHER -> Sustainable Cooking Practices\n",
      "Caruso Family - OWNED -> Amico\n",
      "Caruso Family - MEMBER -> Antonio\n",
      "Caruso Family - MEMBER -> Pietro\n",
      "Caruso Family - MEMBER -> Sofia\n",
      "Caruso Family - MEMBER -> Lucia\n",
      "Caruso Family - BASED_IN -> Rome\n",
      "Caruso Family - BASED_IN -> Los Angeles\n",
      "Caruso Family - HOSTED -> Culinary Workshops\n",
      "Caruso Family - SUPPORTED -> Mentorship Programs\n",
      "Caruso Family - SUPPORTED -> Local Artists\n",
      "Caruso Family - INVOLVED_IN -> Community\n",
      "Caruso Family - COLLABORATED -> Local Musicians\n",
      "Amico - CHILD -> Pietro\n",
      "Amico - CHILD -> Sofia\n",
      "Amico - STUDENT -> Lucia\n",
      "Amico - OWNED -> Amico'S\n",
      "Amico - HOSTED -> Local Artists\n",
      "Amico - INITIATOR -> Farm-To-Table\n",
      "Antonio - PARENT -> Maria\n",
      "Antonio - PARENT -> Giovanni\n",
      "Antonio - INHERITOR -> Antonio\n",
      "Antonio - RELATIVE -> Pietro\n",
      "Antonio - RELATIVE -> Sofia\n",
      "Antonio - CHEF -> Antonio\n",
      "Antonio - RESIDENT -> Island\n",
      "Antonio - TRAVELER -> Italy\n",
      "Antonio - OWNED -> La Dolce Vita\n",
      "Antonio - WORKED_IN -> Santa Caterina\n",
      "Antonio - HEAD_OF_FAMILY -> Caruso Family\n",
      "Antonio - LIVES_IN -> Rome\n",
      "Antonio - ORGANIZER -> Culinary Workshops\n",
      "Pietro - PARENT -> Antonio\n",
      "Pietro - SPOUSE -> Sofia\n",
      "Pietro - OWNER -> Trattoria\n",
      "Pietro - OWNER -> Il Mare Nostrum\n",
      "Pietro - LOCATION -> Sea\n",
      "Pietro - LOCATION -> Village\n",
      "Pietro - MEMBER -> Caruso Family\n",
      "Pietro - TEACHER -> Seafood Preparation\n",
      "Sofia - OWNER -> Trattoria\n",
      "Sofia - OWNER -> La Terra Di Siena\n",
      "Sofia - LOCATION -> Kitchen\n",
      "Sofia - REPRESENTATIVE -> Sicilian Culture\n",
      "Sofia - MEMBER -> Caruso Family\n",
      "Sofia - TEACHER -> Baking\n",
      "Trattoria - LOCATED -> Village\n"
     ]
    }
   ],
   "source": [
    "print(graph_retriever(\"Who is Nonna Lucia?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: \"CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k RETURN reduce(str='', k IN ['text'] | str + '\\\\n' + k + ': ' + coalesce(node[k], '')) AS text, node {.*, `embedding`: Null, id: Null, `text`: Null} AS metadata, score\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph data:\n",
      "Nonna Lucia - ANCESTOR -> Pietro\n",
      "Lucia - OWNER -> Kitchen\n",
      "Lucia - OWNER -> Bella Vita\n",
      "Lucia - SISTER -> Antonio\n",
      "Lucia - GRANDMOTHER -> Amico\n",
      "Lucia - MATRIARCH -> Caruso\n",
      "Lucia - MEMBER -> Caruso Family\n",
      "Lucia - LIVES_IN -> Los Angeles\n",
      "Lucia - TEACHER -> Sustainable Cooking Practices\n",
      "Caruso Family - OWNED -> Amico\n",
      "Caruso Family - MEMBER -> Antonio\n",
      "Caruso Family - MEMBER -> Pietro\n",
      "Caruso Family - MEMBER -> Sofia\n",
      "Caruso Family - MEMBER -> Lucia\n",
      "Caruso Family - BASED_IN -> Rome\n",
      "Caruso Family - BASED_IN -> Los Angeles\n",
      "Caruso Family - HOSTED -> Culinary Workshops\n",
      "Caruso Family - SUPPORTED -> Mentorship Programs\n",
      "Caruso Family - SUPPORTED -> Local Artists\n",
      "Caruso Family - INVOLVED_IN -> Community\n",
      "Caruso Family - COLLABORATED -> Local Musicians\n",
      "Amico - CHILD -> Pietro\n",
      "Amico - CHILD -> Sofia\n",
      "Amico - STUDENT -> Lucia\n",
      "Amico - OWNED -> Amico'S\n",
      "Amico - HOSTED -> Local Artists\n",
      "Amico - INITIATOR -> Farm-To-Table\n",
      "Antonio - PARENT -> Maria\n",
      "Antonio - PARENT -> Giovanni\n",
      "Antonio - INHERITOR -> Antonio\n",
      "Antonio - RELATIVE -> Pietro\n",
      "Antonio - RELATIVE -> Sofia\n",
      "Antonio - CHEF -> Antonio\n",
      "Antonio - RESIDENT -> Island\n",
      "Antonio - TRAVELER -> Italy\n",
      "Antonio - OWNED -> La Dolce Vita\n",
      "Antonio - WORKED_IN -> Santa Caterina\n",
      "Antonio - HEAD_OF_FAMILY -> Caruso Family\n",
      "Antonio - LIVES_IN -> Rome\n",
      "Antonio - ORGANIZER -> Culinary Workshops\n",
      "Pietro - PARENT -> Antonio\n",
      "Pietro - SPOUSE -> Sofia\n",
      "Pietro - OWNER -> Trattoria\n",
      "Pietro - OWNER -> Il Mare Nostrum\n",
      "Pietro - LOCATION -> Sea\n",
      "Pietro - LOCATION -> Village\n",
      "Pietro - MEMBER -> Caruso Family\n",
      "Pietro - TEACHER -> Seafood Preparation\n",
      "Sofia - OWNER -> Trattoria\n",
      "Sofia - OWNER -> La Terra Di Siena\n",
      "Sofia - LOCATION -> Kitchen\n",
      "Sofia - REPRESENTATIVE -> Sicilian Culture\n",
      "Sofia - MEMBER -> Caruso Family\n",
      "Sofia - TEACHER -> Baking\n",
      "Trattoria - LOCATED -> Village\n",
      "vector data:\n",
      "\n",
      "text: Pietro, Antonio's eldest son, was a skilled fisherman who loved the sea as much as the kitchen. His daily catches were the freshest seafood in the village, a staple in the family trattoria he ran with his wife, Sofia. Sofia was a baker par excellence, known for her incredible pastries and bread. Together, they transformed the trattoria into a local institution, famous for its warm hospitality and authentic flavors. The trattoria was a microcosm of Sicilian culture, where stories were shared over plates of fresh pasta and glasses of homemade wine. Pietro and Sofia instilled in their children, including Amico, the values of hard work, respect for tradition, and the joy of feeding others.\n",
      "\n",
      "Nonna Lucia: The Matriarch and Mentor#Document \n",
      "text: Lucia, Antonio's sister and Amico's grandmother, was the matriarch of the Caruso family. A culinary sage, Nonna Lucia was the custodian of the family's recipes, a role she took very seriously. Her kitchen was a sacred space, where she taught her grandchildren the art of Sicilian cooking. Under her watchful eye, Amico learned the delicate balance of flavors in a Caponata and the intricate process of making fresh pasta. Nonna Lucia's influence extended beyond the kitchen; she was a pillar of strength and wisdom, guiding her family with love and a firm hand. Her teachings went beyond recipes, imparting lessons about life, love, and the importance of community.#Document \n",
      "text: Lucia, named after her grandmother and inheriting her culinary talent, brought a piece of Sicily to sunny Los Angeles with \"Bella Vita.\" Lucia was a creative force, combining her grandmother's traditional recipes with her flair for innovation. The restaurant offered a menu that catered to LA's diverse and health-conscious population, featuring dishes like gluten-free pasta and organic salads, alongside indulgent classics like Lasagna and Cannoli. \"Bella Vita's\" rooftop bar, offering panoramic views of the city, became a popular spot for enjoying Italian-inspired cocktails and small plates. Lucia's commitment to sustainability and her support for local artists made \"Bella Vita\" a hub for food, art, and culture.#Document \n",
      "text: Giovanni Caruso, Amico's great-grandfather, was a man of the earth. His calloused hands spoke of years spent cultivating the fertile soils of Santa Caterina, producing olives and grapes that were the pride of the region. Giovanni was not just a farmer but an alchemist of flavors, blending the fruits of his labor into exquisite oils and wines. His wife, Maria, was the soul of the kitchen. A masterful cook, Maria's dishes were a symphony of hearty stews and delicate pastries, passed down from her ancestors and refined with her own touch. The couple's home was a haven of culinary experimentation and love, where their children were introduced to the secrets of the Sicilian kitchen.\n",
      "\n",
      "Antonio Caruso: The Storyteller and Innovator\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "#here we combine the data from graph retriever function and vector index\n",
    "def full_retriever(question: str):\n",
    "    graph_data = graph_retriever(question)\n",
    "    vector_data = [chunk.page_content for chunk in vector_retriever.invoke(question)]\n",
    "    final_data = f\"\"\"Graph data:\n",
    "{graph_data}\n",
    "vector data:\n",
    "{\"#Document \". join(vector_data)}\n",
    "    \"\"\"\n",
    "    return final_data\n",
    "\n",
    "final_context = full_retriever(\"Who is Nonna Lucia?\")\n",
    "print(final_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: \"CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k RETURN reduce(str='', k IN ['text'] | str + '\\\\n' + k + ': ' + coalesce(node[k], '')) AS text, node {.*, `embedding`: Null, id: Null, `text`: Null} AS metadata, score\"\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Use natural language and be concise.\n",
    "Answer:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "        {\n",
    "            \"context\": full_retriever,\n",
    "            \"question\": RunnablePassthrough(),\n",
    "        }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "res = chain.invoke(\"Who is Nonna Lucia? Give brief information about her\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonna Lucia is the matriarch of the Caruso family. She is a culinary sage, known for her traditional Sicilian recipes and her role as a mentor to her grandchildren, teaching them the art of Sicilian cooking. She is also described as a pillar of strength and wisdom, guiding her family with love and a firm hand.\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
